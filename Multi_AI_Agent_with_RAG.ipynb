{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHPfWfNgKO85/gIYyjMVat",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aarushikankanmeli97/Generative_AI/blob/main/Multi_AI_Agent_with_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Multi AI Agent RAG with LangGraph and AstraDB**\n",
        "\n",
        "This project focuses on creating an LLM application which consists of a router node, a wikipedia search node and a vectorDB search node. The application takes in user query based on which the router of this application decides whether to do a wikipedia search or the vectorDB search. The vectorDB contains information from several website pages.\n",
        "\n",
        "The database used here is *AstraDB*.\n",
        "\n",
        "The final response is then passed to the LLM along woth some task specific prompt to get the final result.\n"
      ],
      "metadata": {
        "id": "RNG_6ymXFIzz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzFXZE0JuRGo"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain langchain-community langchain-groq langchainhub langchain-huggingface tiktoken langgraph cassio wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cassio\n",
        "\n",
        "##Connection of the Astra DB\n",
        "ASTRA_DB_APPLICATION_TOKEN=\"****\"\n",
        "ASTRA_DB_ID=\"****\"\n",
        "\n",
        "cassio.init(\n",
        "    token=ASTRA_DB_APPLICATION_TOKEN,\n",
        "    database_id=ASTRA_DB_ID\n",
        ")"
      ],
      "metadata": {
        "id": "Rp47c8ziueQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Build Index\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "# Docs to index\n",
        "urls = [\n",
        "     \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "     \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
        "     \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
        "]\n",
        "\n",
        "## Load the urls\n",
        "docs = [WebBaseLoader(url).load() for url in urls]\n",
        "doc_list = [item for sublist in docs for item in sublist]\n",
        "print(doc_list)\n",
        "## Split the document into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        ")\n",
        "\n",
        "docs_split = text_splitter.split_documents(doc_list)"
      ],
      "metadata": {
        "id": "NMfOpzYIvJBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_split"
      ],
      "metadata": {
        "id": "HMRELbRDwvTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-V2\")\n"
      ],
      "metadata": {
        "id": "2NygKxMTxWWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "astra_vector_store = Cassandra(\n",
        "    embedding = embeddings,\n",
        "    table_name = \"demo\",\n",
        "    session = None,\n",
        "    keyspace = None\n",
        ")"
      ],
      "metadata": {
        "id": "43gbgNlTx3GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "astra_vector_store.add_documents(docs_split)\n",
        "print(\"Inserted %i headlines.\"  % len(docs_split))\n",
        "astra_vector_index=VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
      ],
      "metadata": {
        "id": "DRxul2mFyXbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = astra_vector_store.as_retriever()\n",
        "retriever.invoke(\"What is agent?\")"
      ],
      "metadata": {
        "id": "uNSCufpUy7H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Langgraph application\n",
        "\n",
        "from typing import Literal\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field"
      ],
      "metadata": {
        "id": "JvLueT8h_Fz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Model\n",
        "class RouteQuery(BaseModel):\n",
        "  \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
        "\n",
        "  datasource: Literal[\"vectorstore\", \"wiki_search\"] = Field(\n",
        "      ...,\n",
        "      description = \"Given a user question choose to reoute it to wikipedia or a vectorstore.\",\n",
        "  )"
      ],
      "metadata": {
        "id": "oFZ1mDVm_7o5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "groq_api_key = userdata.get(\"<ENTER GROQ API KEY>\")\n"
      ],
      "metadata": {
        "id": "7aBLpY1AAcCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"llama-3.3-70b-versatile\")\n",
        "llm.invoke(\"Hi\")"
      ],
      "metadata": {
        "id": "8t986ZwUBFvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "structured_llm_router = llm.with_structured_output(RouteQuery)"
      ],
      "metadata": {
        "id": "i6KrZUucBUfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Prompt\n",
        "system = \"\"\"You are an expert at routing a user question to a vectorstore or wikipedia.\n",
        "The vectorstore contains documents related to agents, prompt engineering, and adversarial attacks.\n",
        "Use the vectorstore for questions on these topics. Otherwise, use wiki-search.\"\"\"\n",
        "route_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "question_router = route_prompt | structured_llm_router"
      ],
      "metadata": {
        "id": "8Uopzs-CCOVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(question_router.invoke({\"question\": \"What is agent?\"}))"
      ],
      "metadata": {
        "id": "LbAy8Ha2CdK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(question_router.invoke({\"question\": \"Who was the first person to walk on moon?\"}))"
      ],
      "metadata": {
        "id": "t1-5kv7kCpRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "from langchain_community.tools import WikipediaQueryRun\n",
        "\n",
        "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=500)\n",
        "wiki = WikipediaQueryRun(api_wrapper=api_wrapper)"
      ],
      "metadata": {
        "id": "3xNtu4QNCvUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wiki.run(\"What was Apollo 11 mission?\")"
      ],
      "metadata": {
        "id": "_BhMgUdpDbG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## AI Agent application using LangGraph\n",
        "\n",
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "  \"\"\"\n",
        "  Represents the state of our graph.\n",
        "\n",
        "  Attributes:\n",
        "      question: question\n",
        "      generation: LLM generation\n",
        "      documents: list of documents\n",
        "  \"\"\"\n",
        "\n",
        "  question: str\n",
        "  generation: str\n",
        "  documents: List[str]"
      ],
      "metadata": {
        "id": "q8z8hqM0DfqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import Document\n",
        "\n",
        "def retrieve(state):\n",
        "  \"\"\"\n",
        "    Retrieve documents\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, documents, that contains retrieved documents\n",
        "  \"\"\"\n",
        "  print(\"----Retrieve----\")\n",
        "  questions = state[\"question\"]\n",
        "\n",
        "  ## Retreival\n",
        "\n",
        "  documents = retriever.invoke(questions)\n",
        "  return {\"documents\":documents, \"question\":questions}"
      ],
      "metadata": {
        "id": "nemNULOVEPyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wiki_search(state):\n",
        "    \"\"\"\n",
        "    wiki search based on the re-phrased question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates documents key with appended web results\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---wikipedia---\")\n",
        "\n",
        "    question = state[\"question\"]\n",
        "    print(question)\n",
        "\n",
        "    # Wiki search\n",
        "    docs = wiki.invoke({\"query\": question})\n",
        "    #print(docs[\"summary\"])\n",
        "    wiki_results = docs\n",
        "    wiki_results = Document(page_content=wiki_results)\n",
        "\n",
        "    return {\"documents\": wiki_results, \"question\": question}"
      ],
      "metadata": {
        "id": "vNnMci7MFEHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Edges ###\n",
        "\n",
        "\n",
        "def route_question(state):\n",
        "    \"\"\"\n",
        "    Route question to wiki search or RAG.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Next node to call\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---ROUTE QUESTION---\")\n",
        "    question = state[\"question\"]\n",
        "    source = question_router.invoke({\"question\": question})\n",
        "    if source.datasource == \"wiki_search\":\n",
        "        print(\"---ROUTE QUESTION TO Wiki SEARCH---\")\n",
        "        return \"wiki_search\"\n",
        "    elif source.datasource == \"vectorstore\":\n",
        "        print(\"---ROUTE QUESTION TO RAG---\")\n",
        "        return \"vectorstore\""
      ],
      "metadata": {
        "id": "9HElPFfxFZyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Edges ###\n",
        "\n",
        "\n",
        "def route_question(state):\n",
        "    \"\"\"\n",
        "    Route question to wiki search or RAG.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Next node to call\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---ROUTE QUESTION---\")\n",
        "    question = state[\"question\"]\n",
        "    source = question_router.invoke({\"question\": question})\n",
        "    if source.datasource == \"wiki_search\":\n",
        "        print(\"---ROUTE QUESTION TO Wiki SEARCH---\")\n",
        "        return \"wiki_search\"\n",
        "    elif source.datasource == \"vectorstore\":\n",
        "        print(\"---ROUTE QUESTION TO RAG---\")\n",
        "        return \"vectorstore\""
      ],
      "metadata": {
        "id": "r1xe_9jEGijM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END, StateGraph, START\n",
        "\n",
        "workflow = StateGraph(GraphState)\n",
        "# Define the nodes\n",
        "workflow.add_node(\"wiki_search\", wiki_search)  # web search\n",
        "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
        "\n",
        "# Build graph\n",
        "workflow.add_conditional_edges(\n",
        "    START,\n",
        "    route_question,\n",
        "    {\n",
        "        \"wiki_search\": \"wiki_search\",\n",
        "        \"vectorstore\": \"retrieve\",\n",
        "    },\n",
        ")\n",
        "workflow.add_edge( \"retrieve\", END)\n",
        "workflow.add_edge( \"wiki_search\", END)\n",
        "# Compile\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "2bodzJXIGlrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(app.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "id": "ylO9i3W4Gne7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# Run\n",
        "inputs = {\n",
        "    \"question\": \"What is agent?\"\n",
        "}\n",
        "for output in app.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        # Node\n",
        "        pprint(f\"Node '{key}':\")\n",
        "        # Optional: print full state at each node\n",
        "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
        "    pprint(\"\\n---\\n\")\n",
        "\n",
        "# Final generation\n",
        "pprint(value['documents'][0].dict()['metadata']['description'])"
      ],
      "metadata": {
        "id": "BAX89H3MGprz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# Run\n",
        "inputs = {\n",
        "    \"question\": \"Avengers\"\n",
        "}\n",
        "for output in app.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        # Node\n",
        "        pprint(f\"Node '{key}':\")\n",
        "        # Optional: print full state at each node\n",
        "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
        "    pprint(\"\\n---\\n\")\n",
        "\n",
        "# Final generation\n",
        "pprint(value['documents'])"
      ],
      "metadata": {
        "id": "sEp3SkJlGs2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6mjOgMWHGyPA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}